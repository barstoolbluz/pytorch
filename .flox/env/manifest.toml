## Flox Environment Manifest -----------------------------------------
##
##   _Everything_ you need to know about the _manifest_ is here:
##
##   https://flox.dev/docs/reference/command-reference/manifest.toml/
##
## -------------------------------------------------------------------
# Flox manifest version managed by Flox CLI
version = 1


## Install Packages --------------------------------------------------
##  $ flox install gum  <- puts a package in [install] section below
##  $ flox search gum   <- search for a package
##  $ flox show gum     <- show all versions of a package
## -------------------------------------------------------------------
[install]
python312.pkg-path = "python312"
ninja.pkg-path = "ninja"
#cudatoolkit.pkg-path = "flox-cuda/cudaPackages_12_9.cudatoolkit"
#cudatoolkit.systems = ["x86_64-linux"]
uv.pkg-path = "uv"
gcc.pkg-path = "gcc"
cmake.pkg-path = "cmake"
protobuf.pkg-path = "protobuf"
btop.pkg-path = "btop"
# gum.pkg-path = "gum"
# gum.version = "^0.14.5"


## Environment Variables ---------------------------------------------
##  ... available for use in the activated environment
##      as well as [hook], [profile] scripts and [services] below.
## -------------------------------------------------------------------
[vars]
# INTRO_MESSAGE = "It's gettin' Flox in here"


## Activation Hook ---------------------------------------------------
##  ... run by _bash_ shell when you run 'flox activate'.
## -------------------------------------------------------------------
[hook]
# on-activate = '''
#   # -> Set variables, create files and directories
#   # -> Perform initialization steps, e.g. create a python venv
#   # -> Useful environment variables:
#   #      - FLOX_ENV_PROJECT=/home/user/example
#   #      - FLOX_ENV=/home/user/example/.flox/run
#   #      - FLOX_ENV_CACHE=/home/user/example/.flox/cache
# '''


## Profile script ----------------------------------------------------
## ... sourced by _your shell_ when you run 'flox activate'.
## -------------------------------------------------------------------
[profile]
# common = '''
#   gum style \
#   --foreground 212 --border-foreground 212 --border double \
#   --align center --width 50 --margin "1 2" --padding "2 4" \
#     $INTRO_MESSAGE
# '''
## Shell-specific customizations such as setting aliases go here:
# bash = ...
# zsh  = ...
# fish = ...


## Services ---------------------------------------------------------
##  $ flox services start             <- Starts all services
##  $ flox services status            <- Status of running services
##  $ flox activate --start-services  <- Activates & starts all
## ------------------------------------------------------------------
[services]
# myservice.command = "python3 -m http.server"


## Include ----------------------------------------------------------
## ... environments to create a composed environment
## ------------------------------------------------------------------
[include]
# environments = [
#     { dir = "../common" }
# ]


## Build and publish your own packages ------------------------------
##  $ flox build
##  $ flox publish
## ------------------------------------------------------------------
[build]
[build.pytorch-sm120]
description = "PyTorch EXCLUSIVELY for RTX 5090 - ALL kernels compiled ONLY for SM_120 compute capability. Fixes ComfyUI Conv2D kernel issues."
version = "2.10.0-sm120-cuda13"
command = """
  # Initialize git submodules first
  git submodule update --init --recursive
  
  # LONG-TERM SOLUTION: Focus EXCLUSIVELY on RTX 5090 (SM_120)
  # This ensures ALL kernel compilation resources go to compute capability 12.0
  export TORCH_CUDA_ARCH_LIST="12.0"
  export CUDA_ARCH_LIST="12.0" 
  
  # Force compilation of ALL CUDA kernels ONLY for SM_120
  export TORCH_CUDA_GENCODE="-gencode arch=compute_120,code=sm_120 -gencode arch=compute_120,code=compute_120"
  
  export USE_CUDA=1
  export USE_CUDNN=1
  export USE_CUFILE=0
  export USE_TENSORPIPE=0
  export USE_NCCL=0
  export USE_SYSTEM_PROTOBUF=1
  export BUILD_CUSTOM_PROTOBUF=OFF
  export MAX_JOBS=32
  
  # Force kernel compilation flags - RTX 5090 ONLY
  export CUDA_NVCC_FLAGS="--generate-code arch=compute_120,code=sm_120 --generate-code arch=compute_120,code=compute_120"
  
  # Ensure all PyTorch CUDA operations compile for SM_120
  export BUILD_WITH_CUDA=ON
  export USE_CUDA_STATIC_LINK=0
  
  # Set CUDA paths for local CUDA 13.0 installation
  export CUDA_HOME=/usr/local/cuda-13.0
  export CUDA_ROOT=/usr/local/cuda-13.0
  export CUDATOOLKIT_HOME=/usr/local/cuda-13.0
  export LD_LIBRARY_PATH="$CUDA_HOME/lib64:$CUDA_HOME/lib:$LD_LIBRARY_PATH"
  export LIBRARY_PATH="$CUDA_HOME/lib64:$CUDA_HOME/lib:$LIBRARY_PATH"
  
  # Compiler flags with explicit SM_120 kernel compilation
  export CXXFLAGS="-Wno-error -Wno-nonnull -Wno-array-bounds -Wno-stringop-overflow -O2"
  export CFLAGS="-Wno-error -Wno-nonnull -Wno-array-bounds -Wno-stringop-overflow -O2"
  export NVCCFLAGS="--std=c++17 -Wno-deprecated-gpu-targets --allow-unsupported-compiler --generate-code arch=compute_120,code=sm_120 --generate-code arch=compute_120,code=compute_120"
  
  # Ensure cuDNN kernels compile for SM_120 with CUDA 13.0
  export CUDNN_LIBRARY="$CUDA_HOME/lib64"
  export CUDNN_INCLUDE_DIR="$CUDA_HOME/include"
  export CUDNN_FRONTEND_PATH="$CUDA_HOME/include"
  export FORCE_CUDA_KERNEL_COMPILATION=1
  export TORCH_NVCC_FLAGS="--expt-relaxed-constexpr"
  
  # PyTorch specific flags to force kernel compilation - RTX 5090 EXCLUSIVE
  export TORCH_CUDA_GENCODE_LIST="12.0"
  export CMAKE_CUDA_ARCHITECTURES="120"
  
  # Use local CUDA 13.0 toolkit directly
  export PATH="$CUDA_HOME/bin:$PATH"
  export CUDA_TOOLKIT_ROOT_DIR="$CUDA_HOME"
  
  # Create Python virtual environment
  python3 -m venv build_venv
  source build_venv/bin/activate
  
  # Install Python dependencies
  pip install --upgrade pip setuptools wheel
  pip install cmake ninja six
  pip install -r requirements.txt
  
  # Set up six module for NNPACK
  mkdir -p build/confu-srcs/six
  cp build_venv/lib/python3.12/site-packages/six.py build/confu-srcs/six/__init__.py
  cp build_venv/lib/python3.12/site-packages/six.py build/confu-srcs/
  cp build_venv/lib/python3.12/site-packages/six.py third_party/python-peachpy/
  
  # Build PyTorch
  python setup.py develop
  
  # Install to output directory
  mkdir -p $out/lib/python3.12/site-packages
  cp -r build_venv/lib/python3.12/site-packages/torch* $out/lib/python3.12/site-packages/
  
  # Create wrapper script
  mkdir -p $out/bin
  cat > $out/bin/pytorch-sm120-info << EOF
#!/bin/bash
echo "PyTorch with SM_120 support for RTX 5090"
python3 -c "import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA arch list: {torch.cuda.get_arch_list()}' if torch.cuda.is_available() else 'CUDA not available')"
EOF
  chmod +x $out/bin/pytorch-sm120-info
"""


## Other Environment Options -----------------------------------------
[options]
# Systems that environment is compatible with
# systems = [
#   "aarch64-darwin",
#   "aarch64-linux",
#   "x86_64-darwin",
#   "x86_64-linux",
# ]
# Uncomment to disable CUDA detection.
# cuda-detection = false
